{"cells": [{"cell_type": "markdown", "id": "a71ffa80-4dd0-440b-878e-32e22c734ef6", "metadata": {"slideshow": {"slide_type": "notes"}, "tags": []}, "source": "# Movie Recommendation System"}, {"cell_type": "markdown", "id": "7e2e0f03-355b-4479-9977-37457629215a", "metadata": {}, "source": "## Introduction\n\n#### We will create a movie recommendation system based on the MovieLens dataset available [here.](https://grouplens.org/datasets/movielens/) The data consists of movies ratings (on a scale of 1 to 5).\n\n## Outline\n  1. Import libraries and load the MovieLens dataset <br>\n  2. Handling missing data <br>\n  3. Exploring movielens data <br>\n  4. Collaborative filtering with <br>\n    &emsp;&emsp; I. _ALS_ (before tuning)<br>\n    &emsp;&emsp; II. _ALS_ (after tuning)<br>\n\n## Setup\n"}, {"cell_type": "markdown", "id": "0863ea9b-2311-4027-aa9d-ab600795c5b7", "metadata": {"tags": []}, "source": "#### Step 1. Create a parallel computing cluster by loading configuration settings from a JSON file."}, {"cell_type": "code", "execution_count": null, "id": "90ac0189-3393-4ba6-8e1c-2c66cfa6799c", "metadata": {}, "outputs": [], "source": "import ipyparallel as ipp\n\ncluster = ipp.Cluster.from_file(\"/root/.ipython/profile_default/security/cluster-.json\")\nrc = cluster.connect_client_sync()\nrc"}, {"cell_type": "markdown", "id": "ff27c78a-c9e4-41bf-a5c8-17cb71b82685", "metadata": {"tags": []}, "source": "#### Step 2. Set up a SparkSession using PySpark and import set of built-in functions for data manipulation."}, {"cell_type": "code", "execution_count": null, "id": "c19d5984-19f9-466b-8af1-28eaa45bdb3e", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n\nspark = SparkSession.builder \\\n .appName('MovieRecommendationSystem') \\\n .getOrCreate()\n\n# spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True) # Switch to eager evaluations for debugging"}, {"cell_type": "markdown", "id": "a93de8d3-572b-4d0b-8ea2-03322660cd42", "metadata": {"tags": []}, "source": "#### Step 3. Import the storage module from the google.cloud package, which provides functionality to interact with Google Cloud Storage."}, {"cell_type": "code", "execution_count": null, "id": "72d46bdb", "metadata": {}, "outputs": [], "source": "from google.cloud import storage\n\ngcs_client = storage.Client()\nbucket = gcs_client.bucket('bucket-spark-recommender') # Retrieves a reference to a specific GCS bucket\n\nbucket_path = \"gs://bucket-spark-recommender\""}, {"cell_type": "markdown", "id": "8a5bb1ea-99d6-4775-8407-eae7e620931a", "metadata": {"tags": []}, "source": "## I. Define File Paths and Schema, Load DataFrames."}, {"cell_type": "markdown", "id": "cd809fc4-6c74-456a-ab99-b520ebd0f209", "metadata": {"tags": []}, "source": "##### Load the MovieLens 1 million dataset"}, {"cell_type": "markdown", "id": "fca3e615-a000-4cf4-b600-b5e82f88fe4e", "metadata": {}, "source": "occupation_list = ({'0': 'other', \n                    '1': 'academic/educator', \n                    '2': 'artist', \n                    '3': 'clerical/admin', \n                    '4': 'college/grad student', \n                    '5': 'customer service', \n                    '6': 'doctor/health care', \n                    '7': 'executive/managerial', \n                    '8': 'farmer', \n                    '9': 'homemaker', \n                    '10': 'K-12 student', \n                    '11': 'lawyer', \n                    '12': 'programmer', \n                    '13': 'retired', \n                    '14': 'sales/marketing', \n                    '15': 'scientist', \n                    '16': 'self-employed', \n                    '17': 'technician/engineer', \n                    '18': 'tradesman/craftsman', \n                    '19': 'unemployed', \n                    '20': 'writer' })\n\ngenres_list = [\"unknown\",\"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\nage_list = ({'1':  \"Under 18\", \n            '18':  \"18-24\", \n            '25':  \"25-34\", \n            '35':  \"35-44\", \n            '45':  \"45-49\", \n            '50':  \"50-55\", \n            '56':  \"56+\"})\n\nmovies_path_1m = f\"{bucket_path}/ml-1m/movies.dat\"\nmovies_schema_1m = \"MovieID int, Title string, Genres string\"\n\nmovie_df_1m = (spark.read.schema(movies_schema_1m)\n            .option(\"sep\",\"::\")\n            .format(\"csv\")\n            .load(movies_path_1m)\n)\n\n####################################################################\n\nratings_path_1m = f\"{bucket_path}/ml-1m/ratings.dat\"\nratings_schema_1m = \"UserID int, MovieID int, Rating int, Timestamp long\"\n\nrating_df_1m = (spark.read.schema(ratings_schema_1m)\n            .option(\"sep\",\"::\")\n            .format(\"csv\")\n            .load(ratings_path_1m)\n)\n\n\n####################################################################\n\nusers_path_1m = f\"{bucket_path}/ml-1m/users.dat\"\nusers_schema_1m = \"UserID int, Gender string, Age string, Occupation string, ZipCode string\"\n\nuser_df_1m = (spark.read.schema(users_schema_1m)\n            .option(\"sep\",\"::\")\n            .format(\"csv\")\n            .load(users_path_1m)\n)"}, {"cell_type": "markdown", "id": "106d8c2e-89c6-4d46-b0d4-df7c77ef59bb", "metadata": {"tags": []}, "source": "##### Load the MovieLens 10 million dataset"}, {"cell_type": "markdown", "id": "0d95eedd-e69a-4678-9618-ccdcc9c34d9f", "metadata": {}, "source": "movies_path_10m = f\"{bucket_path}/ml-10M100K/movies.dat\"\nmovies_schema_10m = \"MovieID int, Title string, Genres string\"\n\nmovie_df_10m = (spark.read.schema(movies_schema_10m)\n            .option(\"sep\",\"::\")\n            .format(\"csv\")\n            .load(movies_path_10m)\n)\n\n####################################################################\n\nratings_path_10m = f\"{bucket_path}/ml-10M100K/ratings.dat\"\nratings_schema_10m = \"UserID int, MovieID int, Rating int, Timestamp long\"\n\nrating_df_10m = (spark.read.schema(ratings_schema_10m)\n            .option(\"sep\",\"::\")\n            .format(\"csv\")\n            .load(ratings_path_10m)\n)"}, {"cell_type": "markdown", "id": "69e32971-1fd4-4c9d-a4ef-f81cebdf0f53", "metadata": {"tags": []}, "source": "##### Load the MovieLens 20 million dataset"}, {"cell_type": "markdown", "id": "d1a3f943-2c84-464d-ac5c-edb8d47fcae3", "metadata": {}, "source": "movies_path_20m = f\"{bucket_path}/ml-20m/movies.csv\"\nmovies_schema_20m = \"MovieID int, Title string, Genres string\"\n\nmovie_df_20m = (spark.read.option(\"header\",True).schema(movies_schema_20m)\n            .format(\"csv\")\n            .load(movies_path_20m)\n)\n\n####################################################################\n\nratings_path_20m = f\"{bucket_path}/ml-20m/ratings.csv\"\nratings_schema_20m = \"UserID int, MovieID int, Rating int, Timestamp long\"\n\nrating_df_20m = (spark.read.option(\"header\",True).schema(ratings_schema_20m)\n            .format(\"csv\")\n            .load(ratings_path_20m)\n)"}, {"cell_type": "markdown", "id": "1429ce22-9ad4-4fc5-b5ac-d30dbf63032a", "metadata": {"tags": []}, "source": "##### Load the MovieLens 25 million dataset"}, {"cell_type": "code", "execution_count": null, "id": "76cf3616-77a6-4b14-ad06-6ecc88d8009a", "metadata": {}, "outputs": [], "source": "movies_path_25m = f\"{bucket_path}/ml-25m/movies.csv\"\nmovies_schema_25m = \"MovieID int, Title string, Genres string\"\n\nmovie_df_25m = (spark.read.option(\"header\",True).schema(movies_schema_25m)\n            .format(\"csv\")\n            .load(movies_path_25m)\n)\n\n####################################################################\n\nratings_path_25m = f\"{bucket_path}/ml-25m/ratings.csv\"\nratings_schema_25m = \"UserID int, MovieID int, Rating float, Timestamp long\"\n\nrating_df_25m = (spark.read.option(\"header\",True).schema(ratings_schema_25m)\n            .format(\"csv\")\n            .load(ratings_path_25m)\n)"}, {"cell_type": "code", "execution_count": null, "id": "1b8ccccf-ec8e-4cf0-8e00-3b197e1dccc8", "metadata": {}, "outputs": [], "source": "rating_df_25m.show(10)"}, {"cell_type": "code", "execution_count": null, "id": "00ed7fe0-4054-48c5-856f-33c0a6872665", "metadata": {}, "outputs": [], "source": "movie_df_25m.show(10)"}, {"cell_type": "code", "execution_count": null, "id": "b033517c-46b8-4ab5-aea6-d08a89a16331", "metadata": {}, "outputs": [], "source": "# Merge user, movie, and rating DataFrames on common columns (userID and movieID) using inner joins.\n\ndf_25m = (rating_df_25m.join(movie_df_25m, on=\"movieID\", how=\"inner\"))\ndf_25m.show(10)"}, {"cell_type": "code", "execution_count": null, "id": "b7401882-f481-47c4-91ff-b34007aed03f", "metadata": {}, "outputs": [], "source": "df_25m.describe([\"Rating\"]).show()"}, {"cell_type": "markdown", "id": "f99486ce-99eb-4d4e-a015-53a6ac6a698d", "metadata": {"tags": []}, "source": "## II. Handling missing value"}, {"cell_type": "code", "execution_count": null, "id": "7d16b286-468f-4aaf-8a6f-c51ee0391a4a", "metadata": {}, "outputs": [], "source": "# Count the number of missing values in each column of the DataFrame.\n# Drop rows with null values in any column if found during analysis using na.drop()\ndf_25m.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_25m.columns]).show()"}, {"cell_type": "markdown", "id": "c5fc60b9-5dd8-4bd9-8f8a-86abff2cd8fe", "metadata": {"tags": []}, "source": "## III. Exploring movielens data"}, {"cell_type": "code", "execution_count": null, "id": "97414233-9c2e-4bc4-ad4a-eb3dd085c13e", "metadata": {}, "outputs": [], "source": "# Split the values in the 'Genres' column and map the corresponding values for occupation and age.\ndf2_1m = (df_25m\n         .withColumn(\"Genres\", split(col(\"Genres\"), \"[|]\", -1))\n         )\ngenres_list = [\"unknown\",\"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n# Create feature columns for each movie, incorporating information about their genres.\nfor genre in genres_list:\n    df2_1m = df2_1m.withColumn(genre, when(array_contains(df2_1m.Genres , genre), 1).otherwise(0))"}, {"cell_type": "code", "execution_count": null, "id": "4a18e3bd-b111-417c-aebd-d946306c7958", "metadata": {}, "outputs": [], "source": "import matplotlib.pyplot as plt\n\n# Grouping the DataFrame by \"Rating\" and counting occurrences\nuser_rating_record = df2_1m.groupBy(\"Rating\").count().sort(\"Rating\").collect()\n\n# Extracting ratings and their corresponding counts for plotting\nratings_label = [row[\"Rating\"] for row in user_rating_record]\nratings_counts = [row[\"count\"] for row in user_rating_record]\n\n# Plotting a bar chart for the rating\nplt.bar(ratings_label, ratings_counts, align='center')\n\n# Adding labels and title\nplt.xlabel(\"Rating\")\nplt.ylabel(\"Count\")\nplt.title(\"Rating Histogram\")\n\n# Display the histogram\nplt.show()"}, {"cell_type": "code", "execution_count": null, "id": "cb567e2d-fbd7-4402-9ba3-409bef8641ac", "metadata": {}, "outputs": [], "source": "# Explore genre-wise average ratings and counts\n(df2_1m.withColumn(\"Genres\", explode(col(\"Genres\")))\n    .groupBy(\"Genres\")\n    .agg(avg(\"Rating\").alias(\"avg_ratings\"), count(\"Rating\"))\n    .withColumn(\"avg_ratings\", round(\"avg_ratings\", 2))\n    .sort(col(\"avg_ratings\").desc())\n    .show()\n)"}, {"cell_type": "markdown", "id": "3eb8a0cd-730e-4fe1-9b29-ac02fda4b78b", "metadata": {}, "source": "## Recommendation system filtering"}, {"cell_type": "markdown", "id": "9ca38754-e65b-4173-8596-15ea31201f6b", "metadata": {}, "source": "#### Similarity Measures\n\n1. Cosine Similarity:\n\n- Measures the cosine of the angle between two vectors.\n- High cosine similarity indicates similarity; 0 means orthogonal, 1 means identical.\n- Often used when direction matters more than magnitude.\n\n2. Dot Product:\n\n- Multiplies corresponding components of two vectors and sums the results.\n- Normalized dot product is the same as cosine similarity if vectors are normalized.\n- Higher dot product implies higher similarity.\n\n3. Euclidean Distance:\n\n- Measures the straight-line distance between two vectors in Euclidean space.\n- Smaller distance indicates higher similarity.\n- Squared Euclidean distance (when vectors are normalized) is similar to dot product and cosine up to a constant.\n\n4. Pearson Coefficient\n\n- The Pearson correlation coefficient is a measure of linear correlation between two variables. In the context of recommendation systems, it is used to quantify the similarity between users based on their item ratings.\n- The coefficient ranges from -1 to 1. A value of 1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no correlation."}, {"cell_type": "markdown", "id": "08a69c4a-bcc0-4892-969b-09b824134230", "metadata": {}, "source": "### IV. Collaborative filtering \n\n#### a. ALS _(Alternating Least Squares (ALS) matrix factorization before tuning)_"}, {"cell_type": "code", "execution_count": null, "id": "54a4bbc1-ff66-40ff-a0ff-45ea4a95c10f", "metadata": {}, "outputs": [], "source": "from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.sql import Row\nimport time\n\nratings_df = df_25m.select(\"UserID\", \"MovieID\", \"Rating\")\n\n(train_data, test_data) = ratings_df.randomSplit([0.8, 0.2], seed=42)\n\n# Create ALS model\nals = ALS(\n    userCol=\"UserID\",\n    itemCol=\"MovieID\",\n    ratingCol=\"Rating\",\n    coldStartStrategy=\"drop\",  # Drop any rows with NaN predictions\n    nonnegative=True,  # Ensures that predictions are non-negative\n    implicitPrefs=False,  # Treat ratings as explicit feedback\n    maxIter=5,\n    regParam=0.01\n)\n\n# record start time\nstart = time.time()\n\nmodel = als.fit(train_data)\n\n# record end time\nend = time.time()\n\n#Generating Predictions\npredictions = model.transform(test_data)\n\nprint(\"The time of execution taken by als model for traning is :\",\n      (end-start) * 10**3, \"ms\")"}, {"cell_type": "code", "execution_count": null, "id": "60d9950a-a43f-4906-8bfe-0a051ea80bb8", "metadata": {}, "outputs": [], "source": "# View the predictions\npredictions.show(10)"}, {"cell_type": "code", "execution_count": null, "id": "b28824e3-01b1-4f58-93e0-cf3f7021938b", "metadata": {}, "outputs": [], "source": "# Calculate rmse(Root-mean-square error) and mae (mean absolute error)\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\",predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error = \" + str(rmse) + \"\\n\")\n\nevaluator2 = RegressionEvaluator(metricName=\"mae\", labelCol=\"Rating\",predictionCol=\"prediction\")\nmae = evaluator2.evaluate(predictions)\nprint(\"Mean Absolute Error = \" + str(mae) + \"\\n\")"}, {"cell_type": "code", "execution_count": null, "id": "2c1dc0a6-ecae-4106-b81e-42fc65d20072", "metadata": {}, "outputs": [], "source": "# Generate top 5 movie recommendations for a specific user (e.g., UserID 1)\nuserID = 1\nuserSpecificRecs = model.recommendForUserSubset(spark.createDataFrame([Row(UserID=userID)]), 5)\nprint(\"Top 5 user recommendations for a user 1\")\n# Show the recommendations for the specific user\nuserSpecificRecs_movies = [ row[0][0] for row in userSpecificRecs.select(explode(\"recommendations\")).collect()]\nuserSpecificRecs_movies_df = spark.createDataFrame([Row(MovieID=m,Order=i ) for i, m in enumerate(userSpecificRecs_movies)])\nuserSpecificRecs_movies_df.join(df2_1m.select(\"MovieID\", \"Title\", \"Genres\"), \"MovieID\", \"left\").distinct().sort(\"Order\").show()\n\n# Generate top 5 user recommendations for a specific movie (e.g., MovieID 101)\nmovieID = 101\nmovieSpecificRecs = model.recommendForItemSubset(spark.createDataFrame([Row(MovieID=movieID)]), 5)\nprint(\"Top 5 user recommendations for a specific movie 101\")\n# Show the recommendations for the specific movie\nmovieSpecificRecs_movies = [ row[0][0] for row in movieSpecificRecs.select(explode(\"recommendations\")).collect()]\nmovieSpecificRecs_movies_df = spark.createDataFrame([Row(MovieID=m,Order=i ) for i, m in enumerate(movieSpecificRecs_movies)])\nmovieSpecificRecs_movies_df.join(df2_1m.select(\"MovieID\", \"Title\", \"Genres\"), \"MovieID\", \"left\").distinct().sort(\"Order\").show()"}, {"cell_type": "markdown", "id": "f5e26c0a-80f1-420a-9b98-4c608c233d4e", "metadata": {}, "source": "#### b. ALS _(after tuning)_"}, {"cell_type": "code", "execution_count": null, "id": "d93bf2a7-b852-40e7-8652-8dec41ee3d9e", "metadata": {}, "outputs": [], "source": "# Import the requisite items\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Add hyperparameters and their respective values to param_grid\nparam_grid = (ParamGridBuilder()\n            .addGrid(als.rank, [10, 50, 100, 150])\n            .addGrid(als.regParam, [.01, .05, .1, 0.15])\n            .build())\n            # .addGrid(als.maxIter, [5, 50, 100, 200]) # number of iteration to perform on model training\n      \n    \nprint(\"Num models to be tested: \", len(param_grid))\nevaluator3 = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\",predictionCol=\"prediction\")\nevaluator4 = RegressionEvaluator(metricName=\"mae\", labelCol=\"Rating\",predictionCol=\"prediction\")"}, {"cell_type": "markdown", "id": "75655181-ab6b-4f9b-b628-c8b4a96bcbb3", "metadata": {}, "source": "#### Build Cross Validation Pipeline"}, {"cell_type": "code", "execution_count": null, "id": "3c62eccc-9712-4c95-9a4b-941fa8932b80", "metadata": {}, "outputs": [], "source": "# Build cross validation using CrossValidator\ncv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator3, numFolds=5)\n\n# Confirm cv was built\nprint(cv)"}, {"cell_type": "code", "execution_count": null, "id": "d6232bef-966f-4c3c-b63c-b5af739bc55b", "metadata": {}, "outputs": [], "source": "#Fit cross validator to the 'train' dataset\nstart1 = time.time()\n\nmodel = cv.fit(train_data)\n\nend1 = time.time()\n\n#Extract best model from the cv model above\nbest_model = model.bestModel\n# print(\"The time of execution taken by als model for traning is :\", (end1-start1) * 10**3, \"ms\")"}, {"cell_type": "code", "execution_count": null, "id": "c26791a3-c894-4cc8-839f-ea1152312190", "metadata": {}, "outputs": [], "source": "# Print best_model\nprint(type(best_model))\n\n# Complete the code below to extract the ALS model parameters\nprint(\"*************Best Model Parameters*************\")\n\n# # Print \"Rank\"\nprint(\"Rank:\", best_model._java_obj.parent().getRank())\n\n# Print \"MaxIter\"\nprint(\"MaxIter:\", best_model._java_obj.parent().getMaxIter())\n\n# Print \"RegParam\"\nprint(\"RegParam:\", best_model._java_obj.parent().getRegParam())"}, {"cell_type": "code", "execution_count": null, "id": "d22516b8-391e-4d07-96a8-922c96a39792", "metadata": {}, "outputs": [], "source": "# View the predictions\ntest_predictions = best_model.transform(test_data)"}, {"cell_type": "code", "execution_count": null, "id": "e7e0764d-db2e-4c58-8c90-30ddd8200f3a", "metadata": {}, "outputs": [], "source": "rmse = evaluator3.evaluate(test_predictions)\nprint(\"Root-mean-square error = \" + str(rmse) + \"\\n\")\n\n\nmae = evaluator4.evaluate(test_predictions)\nprint(\"Mean Absolute Error = \" + str(mae) + \"\\n\")"}, {"cell_type": "markdown", "id": "e84bb44c-651f-4025-a43c-0d47f803575e", "metadata": {}, "source": "#### Make Recommendations"}, {"cell_type": "code", "execution_count": null, "id": "ba9f252f-4542-4c63-b763-fc5aee8f9f31", "metadata": {}, "outputs": [], "source": "# Generate top 5 movie recommendations for a specific user (e.g., UserID 1)\nuserID = 1\nuserSpecificRecs = best_model.recommendForUserSubset(spark.createDataFrame([Row(UserID=userID)]), 5)\nprint(\"Top 5 user recommendations for a user 1\")\n# Show the recommendations for the specific user\nuserSpecificRecs_movies = [ row[0][0] for row in userSpecificRecs.select(explode(\"recommendations\")).collect()]\nuserSpecificRecs_movies_df = spark.createDataFrame([Row(MovieID=m,Order=i ) for i, m in enumerate(userSpecificRecs_movies)])\nuserSpecificRecs_movies_df.join(df2_1m.select(\"MovieID\", \"Title\", \"Genres\"), \"MovieID\", \"left\").distinct().sort(\"Order\").show()\n\n# Generate top 5 user recommendations for a specific movie (e.g., MovieID 101)\nmovieID = 101\nmovieSpecificRecs = best_model.recommendForItemSubset(spark.createDataFrame([Row(MovieID=movieID)]), 5)\nprint(\"Top 5 user recommendations for a specific movie 101\")\n# Show the recommendations for the specific movie\nmovieSpecificRecs_movies = [ row[0][0] for row in movieSpecificRecs.select(explode(\"recommendations\")).collect()]\nmovieSpecificRecs_movies_df = spark.createDataFrame([Row(MovieID=m,Order=i ) for i, m in enumerate(movieSpecificRecs_movies)])\nmovieSpecificRecs_movies_df.join(df2_1m.select(\"MovieID\", \"Title\", \"Genres\"), \"MovieID\", \"left\").distinct().sort(\"Order\").show()"}, {"cell_type": "code", "execution_count": null, "id": "b23a482d-7a31-47a7-9707-59c3f980401b", "metadata": {}, "outputs": [], "source": "# Generate n Recommendations for all users\nnrecommendations = best_model.recommendForAllUsers(10)\nnrecommendations.limit(10).show()"}, {"cell_type": "markdown", "id": "8d2a3284-01f0-4e31-9d8f-0113bbef3379", "metadata": {}, "source": "### User-Based Filtering with KNN and Cosine Similarity"}, {"cell_type": "code", "execution_count": null, "id": "b3810c25-1600-480a-80b1-8d19ae120563", "metadata": {}, "outputs": [], "source": "!pip install scikit-surprise\n!pip install tabulate\n!pip install numpy\n!pip install scikit-learn"}, {"cell_type": "code", "execution_count": null, "id": "628f207b-a9dc-421e-8969-853f92372a2c", "metadata": {}, "outputs": [], "source": "from collections import defaultdict\nfrom surprise import SVD\nfrom surprise import accuracy\nfrom surprise import KNNBasic\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom tabulate import tabulate\nfrom surprise import Dataset, SVD\nfrom surprise.model_selection import GridSearchCV\nfrom surprise import AlgoBase, KNNBasic\nfrom surprise.prediction_algorithms.knns import SymmetricAlgo\nfrom surprise import Reader\n\nclass KNNBasicPre(KNNBasic):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def test(self, testset, verbose=False):\n        predictions = [self.predict(uid,\n                                    iid,\n                                    r_ui_trans,\n                                    verbose=verbose)\n                        for (uid, iid, r_ui_trans) in testset ]\n        return predictions\n    \n\nalgo_args=[]\nalgo_kwargs = dict(k=50, sim_options={'name': 'pearson', 'user_based': True, 'verbose' : True})\nknn_algo = KNNBasicPre(*algo_args, **algo_kwargs)\n\nknn_algo.fit(trainset)\npredictions = knn_algo.test(testset)\naccuracy.rmse(predictions)\n\nknn_algo_for_hitrate = algo_class(*algo_args, **algo_kwargs)\n\n# Get hitrate results\nknn_algo_for_hitrate.fit(train_loocv)\nleft_out_predictions = knn_algo_for_hitrate.test(test_loocv)\nloocv_anti_testset = train_loocv.build_anti_testset()\nall_predictions = knn_algo_for_hitrate.test(loocv_anti_testset)\n\n# Get top N\ntopN = defaultdict(list)\nminimumRating = 4.0\nn = 10\nfor userID, movieID, actualRating, estimatedRating, _ in all_predictions:\n    if (estimatedRating >= minimumRating):\n        topN[userID].append((movieID, estimatedRating))\n\nfor userID, ratings in topN.items():\n    ratings.sort(key=lambda x: x[1], reverse=True)\n    topN[userID] = ratings[:n]\n\ntop_n_predicted = topN\n\n# Calculate hitrate\nhits = 0\ntotal = 0\n\n# For each left-out rating\nfor leftOut in left_out_predictions:\n    userID = leftOut[0]\n    leftOutMovieID = leftOut[1]\n    # Is it in the predicted top 10 for this user?\n    hit = False\n    for movieID, predictedRating in top_n_predicted[userID]:\n        if leftOutMovieID == movieID:\n            hit = True\n            break\n    if (hit) :\n        hits += 1\n\n    total += 1\nhitrate = hits/total\n\n# Compute overall precision\nprint(f'HitRate: {hitrate}')\n# Return all_predictions\nif calc_most_similar:\n    if hasattr(knn_algo_for_hitrate, 'qi'):\n        sims = knn_algo_for_hitrate.qi\n    else:\n        sims = knn_algo_for_hitrate.sim\n\n    # get_most_similar_movies\n    inner_movie_id = train_loocv.to_inner_iid(target_movie_id)\n    sims = cosine_similarity(sims, sims)\n    target_movie_sims_sorted = [train_loocv.to_raw_iid(x) for x in np.argsort(sims[inner_movie_id])[::-1]]\n    most_similar_movies = movies_df.loc[target_movie_sims_sorted].iloc[:top_k]\n    print(f'Most similar movies to {movies_df.loc[target_movie_id].movie_name}:')\n    print(tabulate(most_similar_movies.head(top_k)[['movie_name', 'genre']], headers='keys'))\n\n# filter prediction for user\ntop_k=10\ntop_preds = sorted([pred for pred in all_predictions if pred.uid == target_user_id], key=lambda pred: pred.est, reverse=True)[:top_k]\nmovie_ids = [pred.iid for pred in top_preds]\nrelevant_movies = movies_df.loc[movie_ids]\nrelevant_movies['rating'] = [pred.est for pred in top_preds]\n\nprint(f'Top predictions for user {target_user_id}:')\nprint(tabulate(relevant_movies.head(top_k)[['movie_name', 'genre']], headers='keys'))"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}, "toc-showmarkdowntxt": true}, "nbformat": 4, "nbformat_minor": 5}